{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c82e95f",
   "metadata": {},
   "source": [
    "### Loading in libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cba36c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import PyPDF2\n",
    "from IPython.display import Audio, display, clear_output, HTML\n",
    "from time import sleep\n",
    "import base64\n",
    "import json\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part, SafetySetting\n",
    "import fitz\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import random\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91845b2",
   "metadata": {},
   "source": [
    "### Load in text for a page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "96cfe176",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAGE_NUMBER = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5503c117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For free distribution For free distribution6 7\n",
      "Listen, count and say.\n",
      "10\n",
      "ten\n",
      "6\n",
      "six\n",
      "7\n",
      "seven\n",
      "8\n",
      "eight\n",
      "9\n",
      "nine\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pdf_file_path = 'data/grade_3_english_book.pdf'\n",
    "\n",
    "with open(pdf_file_path, 'rb') as file:\n",
    "    pdf_reader = PyPDF2.PdfReader(file)\n",
    "    page_number = PAGE_NUMBER\n",
    "    page = pdf_reader.pages[page_number]\n",
    "    text = page.extract_text()\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b9e2df",
   "metadata": {},
   "source": [
    "### Convert page to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "204d08a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 16 saved as data/grade_3_english_book_page_16.png\n"
     ]
    }
   ],
   "source": [
    "pdf_file_path = 'data/grade_3_english_book.pdf'\n",
    "pdf_document = fitz.open(pdf_file_path)\n",
    "\n",
    "page = pdf_document.load_page(PAGE_NUMBER)\n",
    "pix = page.get_pixmap()\n",
    "\n",
    "image_path = f\"data/grade_3_english_book_page_{PAGE_NUMBER+1}.png\"\n",
    "pix.save(image_path)\n",
    "\n",
    "print(f\"Page {PAGE_NUMBER + 1} saved as {image_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d320b774",
   "metadata": {},
   "source": [
    "### Visualizing the blocks for the page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7988a5e8",
   "metadata": {},
   "source": [
    "- Blocks seperate text based on where they belong \n",
    "- This helps us group together the things that belong together\n",
    "- Save image as blocks\n",
    "- Group the words and their bounding boxes by their blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c15dd4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated page saved as output/annotated_page_16_blocks.png\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "pdf_file_path = 'data/grade_3_english_book.pdf'\n",
    "pdf_document = fitz.open(pdf_file_path)\n",
    "\n",
    "#since we want the bounding boxes, block number, line number, & word numbers for each word in the page\n",
    "page = pdf_document.load_page(PAGE_NUMBER)\n",
    "words = page.get_text(\"words\")\n",
    "\n",
    "# each item in 'words' is a tuple:\n",
    "# (x0, y0, x1, y1, word, block_no, line_no, word_no)\n",
    "\n",
    "pix = page.get_pixmap()\n",
    "image = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "block_numbers = set(w[5] for w in words)\n",
    "color_palette = {}\n",
    "for block_no in block_numbers:\n",
    "    color = tuple(random.randint(0, 255) for _ in range(3))\n",
    "    color_palette[block_no] = color\n",
    "\n",
    "try:\n",
    "    font = ImageFont.truetype(\"arial.ttf\", size=14)\n",
    "except IOError:\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "for word_info in words:\n",
    "    x0, y0, x1, y1, word, block_no, line_no, word_no = word_info\n",
    "    rect = [(x0, y0), (x1, y1)]\n",
    "    color = color_palette[block_no]\n",
    "    draw.rectangle(rect, outline=color, width=2)\n",
    "    if word_no == 0 and line_no == 0:\n",
    "        label_position = (x0, y0 - 15)\n",
    "        draw.text(label_position, f\"Block {block_no}\", fill=color, font=font)\n",
    "\n",
    "image_path = f\"output/annotated_page_{PAGE_NUMBER+1}_blocks.png\"\n",
    "image.save(image_path)\n",
    "print(f\"Annotated page saved as {image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "308bb9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: For\n",
      "Coordinates: (33.53379821777344, 738.6478881835938, 49.54179763793945, 755.0518798828125)\n",
      "Block: 0, Line: 0, Word No: 0\n",
      "---\n",
      "Word: free\n",
      "Coordinates: (52.265804290771484, 738.6478881835938, 69.52179718017578, 755.0518798828125)\n",
      "Block: 0, Line: 0, Word No: 1\n",
      "---\n",
      "Word: distribution\n",
      "Coordinates: (72.24579620361328, 738.6478881835938, 127.91380310058594, 755.0518798828125)\n",
      "Block: 0, Line: 0, Word No: 2\n",
      "---\n",
      "Word: 6\n",
      "Coordinates: (38.060001373291016, 18.79998779296875, 53.480003356933594, 60.019989013671875)\n",
      "Block: 1, Line: 0, Word No: 0\n",
      "---\n",
      "Word: Listen,\n",
      "Coordinates: (62.29439926147461, 51.608978271484375, 122.89439392089844, 75.4289779663086)\n",
      "Block: 2, Line: 0, Word No: 0\n",
      "---\n",
      "Word: count\n",
      "Coordinates: (126.89439392089844, 51.608978271484375, 181.2144012451172, 75.4289779663086)\n",
      "Block: 2, Line: 0, Word No: 1\n",
      "---\n",
      "Word: and\n",
      "Coordinates: (186.014404296875, 51.608978271484375, 222.93441772460938, 75.4289779663086)\n",
      "Block: 2, Line: 0, Word No: 2\n",
      "---\n",
      "Word: say.\n",
      "Coordinates: (227.93441772460938, 51.608978271484375, 263.9544372558594, 75.4289779663086)\n",
      "Block: 2, Line: 0, Word No: 3\n",
      "---\n",
      "Word: 10\n",
      "Coordinates: (499.6839904785156, 630.9380493164062, 527.2779541015625, 658.1597290039062)\n",
      "Block: 3, Line: 0, Word No: 0\n",
      "---\n",
      "Word: ten\n",
      "Coordinates: (491.458984375, 677.738037109375, 521.6837158203125, 704.959716796875)\n",
      "Block: 4, Line: 0, Word No: 0\n",
      "---\n",
      "Word: 6\n",
      "Coordinates: (515.56298828125, 120.278076171875, 529.35693359375, 147.499755859375)\n",
      "Block: 5, Line: 0, Word No: 0\n",
      "---\n",
      "Word: six\n",
      "Coordinates: (504.0379943847656, 167.07806396484375, 530.3379516601562, 194.29974365234375)\n",
      "Block: 6, Line: 0, Word No: 0\n",
      "---\n",
      "Word: 7\n",
      "Coordinates: (504.9989929199219, 240.87808227539062, 518.79296875, 268.0997619628906)\n",
      "Block: 7, Line: 0, Word No: 0\n",
      "---\n",
      "Word: seven\n",
      "Coordinates: (492.52398681640625, 287.6780700683594, 547.2487182617188, 314.8997497558594)\n",
      "Block: 8, Line: 0, Word No: 0\n",
      "---\n",
      "Word: 8\n",
      "Coordinates: (514.030029296875, 354.87408447265625, 527.823974609375, 382.09576416015625)\n",
      "Block: 9, Line: 0, Word No: 0\n",
      "---\n",
      "Word: eight\n",
      "Coordinates: (492.530029296875, 402.74908447265625, 542.0299682617188, 429.97076416015625)\n",
      "Block: 10, Line: 0, Word No: 0\n",
      "---\n",
      "Word: 9\n",
      "Coordinates: (507.125, 482.85906982421875, 520.9189453125, 510.08074951171875)\n",
      "Block: 11, Line: 0, Word No: 0\n",
      "---\n",
      "Word: nine\n",
      "Coordinates: (492.5249938964844, 529.6590576171875, 532.4000244140625, 556.8807373046875)\n",
      "Block: 12, Line: 0, Word No: 0\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "words_with_coords = []\n",
    "for w in words:\n",
    "    x0, y0, x1, y1, word, block_no, line_no, word_no = w\n",
    "    word_info = {\n",
    "        'text': word,\n",
    "        'bbox': (x0, y0, x1, y1),\n",
    "        'block_no': block_no,\n",
    "        'line_no': line_no,\n",
    "        'word_no': word_no\n",
    "    }\n",
    "    words_with_coords.append(word_info)\n",
    "\n",
    "for word_info in words_with_coords:\n",
    "    print(f\"Word: {word_info['text']}\")\n",
    "    print(f\"Coordinates: {word_info['bbox']}\")\n",
    "    print(f\"Block: {word_info['block_no']}, Line: {word_info['line_no']}, Word No: {word_info['word_no']}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88751d0f",
   "metadata": {},
   "source": [
    "### Cleaning text and applying SSML tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc66bb8",
   "metadata": {},
   "source": [
    "- Remove noisy text in the page\n",
    "- Apply SSML tags (need refinement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "293eb9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    vertexai.init(project=\"syy-eag-np-61cd\", location=\"us-central1\")\n",
    "    model = GenerativeModel(\n",
    "        \"gemini-1.5-flash-002\",\n",
    "    )\n",
    "    responses = model.generate_content(\n",
    "        [prompt],\n",
    "        generation_config=generation_config,\n",
    "        safety_settings=safety_settings,\n",
    "        stream=False,\n",
    "    )\n",
    "    \n",
    "    return responses.text\n",
    "\n",
    "def remove_code_blocks(text):\n",
    "    lines = text.splitlines()\n",
    "    cleaned_lines = [line for line in lines if not line.startswith('```') and 'xml' not in line]\n",
    "    \n",
    "    cleaned_text = \"\\n\".join(cleaned_lines)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "prompt = f\"\"\"You are professional text to speech transcriber.\n",
    "Your goal is to add SSML tags to make plain text more human-like whilst ensuring it is easy for students to understand.\n",
    "\n",
    "Consider the following steps when transforming plain text.\n",
    "\n",
    "STEP 1: Read the plain text and remove any unnecessary text that is not part of the story (page numbers, publication names, etc). Do not change the text that is part of the story.\n",
    "STEP 2: Identify the best way to make the story natural & human-like.\n",
    "STEP 3: Include the necessary SSML tags to make the story natural and have a nicer flow.\n",
    "STEP 4: Ensure the output is ready to be loaded in with AWS Polly.\n",
    "\n",
    "Plain text input:\n",
    "Hello! Today, we are going to learn a new story. Are you ready?\n",
    "Once upon a time, there was a little cat who loved to play. The cat’s name was Whiskers.\n",
    "Whiskers had a best friend, a big, brown dog named Buddy.\n",
    "One day, Whiskers and Buddy decided to go on an adventure. They wanted to find a hidden treasure!\n",
    "First, they went to the forest. The forest was big and quiet, and Whiskers felt a little scared.\n",
    "But Buddy said, “Don’t worry, Whiskers! I’m here with you.” And Whiskers felt brave.\n",
    "Let’s stop here. Did you understand the story? Let’s say the words together: Whiskers and Buddy.\n",
    "Great job! Let’s continue the story next time.\n",
    "\n",
    "SSML Output:\n",
    "<speak>\n",
    "  <prosody rate=\\\"slow\\\">\n",
    "   Hello! Today, we are going to <emphasis level=\\\"strong\\\">learn</emphasis> a new story. Are you <emphasis level=\\\"moderate\\\">ready</emphasis>?\n",
    "  </prosody>\n",
    "  <break time=\\\"1s\\\"/>\n",
    "   Once upon a time, there was a little <emphasis level=\\\"moderate\\\">cat</emphasis> who loved to play. The cat’s name was Whiskers.\n",
    "  <break time=\\\"500ms\\\"/>\n",
    "   <emphasis level=\\\"strong\\\">Whiskers</emphasis> had a best friend, a big, brown <emphasis level=\\\"moderate\\\">dog</emphasis> named Buddy.\n",
    "  <break time=\\\"1s\\\"/>\n",
    "   One day, <emphasis level=\\\"moderate\\\">Whiskers</emphasis> and <emphasis level=\\\"moderate\\\">Buddy</emphasis> decided to go on an <emphasis level=\\\"strong\\\">adventure</emphasis>. They wanted to find a hidden treasure!\n",
    "  <break time=\\\"1s\\\"/>\n",
    "   First, they went to the <emphasis level=\\\"strong\\\">forest</emphasis>. The forest was <prosody rate=\\\"slow\\\">big and quiet</prosody>, and <emphasis level=\\\"moderate\\\">Whiskers</emphasis> felt a little <emphasis level=\\\"moderate\\\">scared</emphasis>.\n",
    "  <break time=\\\"1s\\\"/>\n",
    "   But Buddy said, “<prosody rate=\\\"slow\\\" volume=\\\"x-loud\\\">Don’t worry, Whiskers! I’m here with you.</prosody>” And <emphasis level=\\\"moderate\\\">Whiskers</emphasis> felt <emphasis level=\\\"strong\\\">brave</emphasis>.\n",
    "  <break time=\\\"1.5s\\\"/>\n",
    "   Let’s <emphasis level=\\\"strong\\\">stop</emphasis> here. Did you understand the story? Let’s say the words together: <break time=\\\"500ms\\\"/> <emphasis level=\\\"moderate\\\">Whiskers</emphasis> and <emphasis level=\\\"moderate\\\">Buddy</emphasis>.\n",
    "  <break time=\\\"500ms\\\"/>\n",
    "   Great job! Let’s continue the story next time.\n",
    "</speak>\n",
    "\n",
    "Plain text input: {text}\n",
    "\n",
    "SSML Output:\"\"\"\n",
    "\n",
    "generation_config = {\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"temperature\": 0.1,\n",
    "    \"top_p\": 0.95,\n",
    "}\n",
    "\n",
    "safety_settings = [\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b9e278c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<speak>\n",
      "  <prosody rate=\"slow\">Listen, count and say.</prosody>\n",
      "  <break time=\"1s\"/>\n",
      "  <say-as interpret-as=\"cardinal\">10</say-as>\n",
      "  <break time=\"500ms\"/>\n",
      "  <say-as interpret-as=\"characters\">ten</say-as>\n",
      "  <break time=\"500ms\"/>\n",
      "  <say-as interpret-as=\"cardinal\">6</say-as>\n",
      "  <break time=\"500ms\"/>\n",
      "  <say-as interpret-as=\"characters\">six</say-as>\n",
      "  <break time=\"500ms\"/>\n",
      "  <say-as interpret-as=\"cardinal\">7</say-as>\n",
      "  <break time=\"500ms\"/>\n",
      "  <say-as interpret-as=\"characters\">seven</say-as>\n",
      "  <break time=\"500ms\"/>\n",
      "  <say-as interpret-as=\"cardinal\">8</say-as>\n",
      "  <break time=\"500ms\"/>\n",
      "  <say-as interpret-as=\"characters\">eight</say-as>\n",
      "  <break time=\"500ms\"/>\n",
      "  <say-as interpret-as=\"cardinal\">9</say-as>\n",
      "  <break time=\"500ms\"/>\n",
      "  <say-as interpret-as=\"characters\">nine</say-as>\n",
      "</speak>\n"
     ]
    }
   ],
   "source": [
    "ssml_output = generate()\n",
    "ssml_output = remove_code_blocks(ssml_output)\n",
    "print(ssml_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3d223c",
   "metadata": {},
   "source": [
    "### Creating speech markers JSON and audio Mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "29d5b715",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session(profile_name='123233845129_DevOpsUser', region_name='us-east-1')\n",
    "polly_client = session.client('polly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "131a998d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': 6, 'type': 'word', 'start': 31, 'end': 37, 'value': 'Listen'}\n",
      "{'time': 811, 'type': 'word', 'start': 39, 'end': 44, 'value': 'count'}\n",
      "{'time': 1135, 'type': 'word', 'start': 45, 'end': 48, 'value': 'and'}\n",
      "{'time': 1309, 'type': 'word', 'start': 49, 'end': 52, 'value': 'say'}\n",
      "{'time': 1811, 'type': 'word', 'start': 66, 'end': 84, 'value': '<break time=\"1s\"/>'}\n",
      "{'time': 3198, 'type': 'word', 'start': 119, 'end': 121, 'value': '10'}\n",
      "{'time': 3754, 'type': 'word', 'start': 133, 'end': 154, 'value': '<break time=\"500ms\"/>'}\n",
      "{'time': 4349, 'type': 'word', 'start': 191, 'end': 194, 'value': 'ten'}\n",
      "{'time': 5102, 'type': 'word', 'start': 206, 'end': 227, 'value': '<break time=\"500ms\"/>'}\n",
      "{'time': 5695, 'type': 'word', 'start': 262, 'end': 263, 'value': '6'}\n",
      "{'time': 6357, 'type': 'word', 'start': 275, 'end': 296, 'value': '<break time=\"500ms\"/>'}\n",
      "{'time': 6950, 'type': 'word', 'start': 333, 'end': 336, 'value': 'six'}\n",
      "{'time': 7940, 'type': 'word', 'start': 348, 'end': 369, 'value': '<break time=\"500ms\"/>'}\n",
      "{'time': 8540, 'type': 'word', 'start': 404, 'end': 405, 'value': '7'}\n",
      "{'time': 9205, 'type': 'word', 'start': 417, 'end': 438, 'value': '<break time=\"500ms\"/>'}\n",
      "{'time': 9803, 'type': 'word', 'start': 475, 'end': 480, 'value': 'seven'}\n",
      "{'time': 10970, 'type': 'word', 'start': 492, 'end': 513, 'value': '<break time=\"500ms\"/>'}\n",
      "{'time': 11563, 'type': 'word', 'start': 548, 'end': 549, 'value': '8'}\n",
      "{'time': 12079, 'type': 'word', 'start': 561, 'end': 582, 'value': '<break time=\"500ms\"/>'}\n",
      "{'time': 12680, 'type': 'word', 'start': 619, 'end': 624, 'value': 'eight'}\n",
      "{'time': 13977, 'type': 'word', 'start': 636, 'end': 657, 'value': '<break time=\"500ms\"/>'}\n",
      "{'time': 14577, 'type': 'word', 'start': 692, 'end': 693, 'value': '9'}\n",
      "{'time': 15166, 'type': 'word', 'start': 705, 'end': 726, 'value': '<break time=\"500ms\"/>'}\n",
      "{'time': 15766, 'type': 'word', 'start': 763, 'end': 767, 'value': 'nine'}\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "ssml_text = ssml_output\n",
    "\n",
    "# generate & save the mp3 for the ssml generated, swap to neural for prod\n",
    "response = polly_client.synthesize_speech(\n",
    "    Engine='standard',\n",
    "    OutputFormat='mp3',\n",
    "    Text=ssml_text,\n",
    "    TextType='ssml',\n",
    "    VoiceId='Joanna'\n",
    ")\n",
    "\n",
    "audio_stream = response.get('AudioStream')\n",
    "audio_file_path = os.path.join(output_dir, f\"page_{PAGE_NUMBER+1}_audio.mp3\")\n",
    "with open(audio_file_path, 'wb') as audio_file:\n",
    "    audio_file.write(audio_stream.read())\n",
    "\n",
    "# generate & save the json with the speech markers \n",
    "speech_marks_response = polly_client.synthesize_speech(\n",
    "    Engine='standard',\n",
    "    OutputFormat='json',\n",
    "    Text=ssml_text,\n",
    "    TextType='ssml',\n",
    "    VoiceId='Joanna',\n",
    "    SpeechMarkTypes=['word']\n",
    ")\n",
    "\n",
    "speech_marks_stream = speech_marks_response.get('AudioStream').read().decode('utf-8')\n",
    "speech_marks = [json.loads(line) for line in speech_marks_stream.strip().split('\\n') if line]\n",
    "\n",
    "speech_marks_file_path = os.path.join(output_dir, f\"page_{PAGE_NUMBER+1}_speech_marks.json\")\n",
    "with open(speech_marks_file_path, 'w') as json_file:\n",
    "    json.dump(speech_marks, json_file, indent=2)\n",
    "\n",
    "for mark in speech_marks:\n",
    "    print(mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc3174a",
   "metadata": {},
   "source": [
    "### Sync together speech words with blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0a7d9f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"output/page_{PAGE_NUMBER+1}_speech_marks.json\", 'r') as json_file:\n",
    "    speech_marks = json.load(json_file)\n",
    "\n",
    "# function to identify words with the ssml tags \n",
    "def is_valid_word(mark):\n",
    "    word = mark['value']\n",
    "    if word.startswith('<') and word.endswith('/>'):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "speech_marks_filtered = [mark for mark in speech_marks if is_valid_word(mark)]\n",
    "\n",
    "# get rid of the punctuations\n",
    "def normalize_word(word):\n",
    "    word = word.lower()\n",
    "    word = re.sub(r'[^\\w\\s]', '', word)\n",
    "    return word\n",
    "\n",
    "for mark in speech_marks_filtered:\n",
    "    mark['normalized_value'] = normalize_word(mark['value'])\n",
    "    \n",
    "for word_info in words_with_coords:\n",
    "    word_info['normalized_text'] = normalize_word(word_info['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "212265b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "# get the list of normalized words and match the blocks\n",
    "speech_normalized_words = [mark['normalized_value'] for mark in speech_marks_filtered]\n",
    "pdf_normalized_words = [info['normalized_text'] for info in words_with_coords]\n",
    "\n",
    "matcher = SequenceMatcher(None, speech_normalized_words, pdf_normalized_words)\n",
    "matching_blocks = matcher.get_matching_blocks()\n",
    "\n",
    "# build a mapping from speech marks to PDF words\n",
    "word_mappings = []\n",
    "for block in matching_blocks:\n",
    "    i, j, n = block\n",
    "    for k in range(n):\n",
    "        speech_index = i + k\n",
    "        pdf_index = j + k\n",
    "        word_mappings.append({\n",
    "            'speech_mark': speech_marks_filtered[speech_index],\n",
    "            'pdf_word_info': words_with_coords[pdf_index]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5a53aeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'time_ms': 6, 'bbox': (62.29439926147461, 51.608978271484375, 122.89439392089844, 75.4289779663086)}, {'time_ms': 811, 'bbox': (126.89439392089844, 51.608978271484375, 181.2144012451172, 75.4289779663086)}, {'time_ms': 1135, 'bbox': (186.014404296875, 51.608978271484375, 222.93441772460938, 75.4289779663086)}, {'time_ms': 1309, 'bbox': (227.93441772460938, 51.608978271484375, 263.9544372558594, 75.4289779663086)}, {'time_ms': 3198, 'bbox': (499.6839904785156, 630.9380493164062, 527.2779541015625, 658.1597290039062)}, {'time_ms': 4349, 'bbox': (491.458984375, 677.738037109375, 521.6837158203125, 704.959716796875)}, {'time_ms': 5695, 'bbox': (515.56298828125, 120.278076171875, 529.35693359375, 147.499755859375)}, {'time_ms': 6950, 'bbox': (504.0379943847656, 167.07806396484375, 530.3379516601562, 194.29974365234375)}, {'time_ms': 8540, 'bbox': (504.9989929199219, 240.87808227539062, 518.79296875, 268.0997619628906)}, {'time_ms': 9803, 'bbox': (492.52398681640625, 287.6780700683594, 547.2487182617188, 314.8997497558594)}, {'time_ms': 11563, 'bbox': (514.030029296875, 354.87408447265625, 527.823974609375, 382.09576416015625)}, {'time_ms': 12680, 'bbox': (492.530029296875, 402.74908447265625, 542.0299682617188, 429.97076416015625)}, {'time_ms': 14577, 'bbox': (507.125, 482.85906982421875, 520.9189453125, 510.08074951171875)}, {'time_ms': 15766, 'bbox': (492.5249938964844, 529.6590576171875, 532.4000244140625, 556.8807373046875)}]\n"
     ]
    }
   ],
   "source": [
    "mapped_words = []\n",
    "for mapping in word_mappings:\n",
    "    time_ms = mapping['speech_mark']['time']\n",
    "    bbox = mapping['pdf_word_info']['bbox']\n",
    "    mapped_words.append({\n",
    "        'time_ms': time_ms,\n",
    "        'bbox': bbox\n",
    "    })\n",
    "    \n",
    "print(mapped_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376c09f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
